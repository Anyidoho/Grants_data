<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SenSE: Smart Grasper for Intelligent Surgical Manipulation</AwardTitle>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>740168.00</AwardTotalIntnAmount>
<AwardAmount>740168</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Wendy Nilsen</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project will develop a novel innovative smart surgical instrument as a multimodal sensing system to advance surgical health care. Modern surgical paradigms, including minimally invasive laparoscopic surgery and robotic assisted surgery, have deprived surgeons of important tactile information that this project aims to partially restore and expand into new dimensions. This project builds a tiny multimodal system that includes optical, electrical, thermal, mechanical and ultrasound sensors that is affixed to a basic surgical device such as a grasper or scalpel (either hand-held or used by an advanced surgical robot). This will turn the device into a diagnostic instrument able to measure blood oxygenation (SpO2), physical damage, and potentially other tissue states like cancer. Advances in machine intelligence are required to process this raw, multidimensional, data into information that is clinically useful to the surgeon. This novel system will promote safer and more effective manipulation of tissues in complex surgical situations protecting delicate tissues easily damaged unintentionally or tissues that are hard to visually identify. The project will support graduate and undergraduate students, including from underrepresented groups, in their STEM studies, and support participation by the PIs and students in outreach events designed to promote and broaden participation in STEM educational programs. &lt;br/&gt;&lt;br/&gt;This project, proposed by a multidisciplinary team, aims to advance health discovery through combining advanced machine learning with a novel multimodal sensing system aimed at improved surgical outcomes. This project will obtain the first ever simultaneous in-vivo measurements of pulse oximetry (blood oxygen saturation, SO2), temperature, electrical impedance (1-100kHz), pressure, and acoustic properties at multiple sites in multiple functioning organs. It will develop, test, and demonstrate a novel, highly integrated, multimodal sensing surgical grasper suitable for endoscopic use. The instrument will generate a continuous stream of a new type of sensed data specific to surgical work with tissues. This project will generate the first such database of in-vitro and in-vivo data along with ground truth from surgical videos, imaging studies, expert evaluations, and post-operative pathological analysis of tissues. The new data set will be shared openly online via an achieved open repository. The new classification and clustering machine learning systems will correlate measured tissue properties with organ anatomy and physiology, especially at interfaces between tissues, aiding in surgical planning and execution, and potentially supporting new modes of clinical care.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/10/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/14/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2036255</AwardID>
<Investigator>
<FirstName>Mika</FirstName>
<LastName>Sinanan</LastName>
<EmailAddress>mssurg@u.washington.edu</EmailAddress>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Eli</FirstName>
<LastName>Shlizerman</LastName>
<EmailAddress>shlizee@uw.edu</EmailAddress>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Blake</FirstName>
<LastName>Hannaford</LastName>
<EmailAddress>blake@ee.washington.edu</EmailAddress>
<StartDate>09/10/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Washington</Name>
<CityName>Seattle</CityName>
<ZipCode>981950001</ZipCode>
<PhoneNumber>2065434043</PhoneNumber>
<StreetAddress>4333 Brooklyn Ave NE</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Washington</StateName>
<StateCode>WA</StateCode>
</Institution>
<ProgramElement>
<Code>143Y</Code>
<Text>PrecisionHlth Sensors w AI-ML</Text>
</ProgramElement>
<ProgramElement>
<Code>7454</Code>
<Text>MSPA-INTERDISCIPLINARY</Text>
</ProgramElement>
<Appropriation>
<Code>0120</Code>
</Appropriation>
</Award>
</rootTag>
