<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>CHS: Small: An Analysis-and-Synthesis Framework for Small Group Conversations</AwardTitle>
<AwardEffectiveDate>10/01/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>477733.00</AwardTotalIntnAmount>
<AwardAmount>477733</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Balakrishnan Prabhakaran</SignBlockName>
</ProgramOfficer>
<AbstractNarration>As one of the most common forms of human-human communication, group conversation is essential to our daily life. Humans can intrinsically manage and regulate a group conversation via the concerted effort of gaze, head movement, and hand gesture. However, research communities only gain limited knowledge and insight on its pattern and mechanism. Understanding and modeling its structure, mechanism, and interaction patterns can not only help to reveal the science of group conversation but also find numerical potential applications in science and engineering. Computationally modeling and generation of group conversations can provide a potential transformative paradigm to empower the group conversational capability on machines and engineering systems, including virtual agents, humanoid robots, and Internet of Things, so that they can follow real-world social norms while interacting with humans. Also, it can significantly facilitate the creation of more socially-engaging and life-like digital humans in education, simulation, and virtual world applications. Furthermore, this project will support the training of a diverse cohort of graduate and undergraduate students at the University of Houston.&lt;br/&gt;&lt;br/&gt;The project addresses the research question: whether and how we can computationally analyze small group conversations and further holistically synthesize life-like group conversational motion for a variety of potential applications? Most existing research works have approached this problem using aggregated methods of analysis on the computation of various average quantities or statistical measures. This project takes a different approach and addresses this problem by computationally modeling the group conversation behaviors and leverages this model to holistically synthesize life-like group conversational motion for a variety of potential applications. The research team will first acquire, in-house, a high quality, small group conversational motion dataset that includes acoustic speech, facial expression, gaze, head movement, hand gesture, and body movement. Based on this dataset, the project will work towards the objectives by focusing on three inter-related research thrusts. The first research thrust is to develop a computational analysis model to extract and compare meaningful gaze patterns for turn-taking and turn-keeping in small group conversations. With the insight obtained from the first thrust, the second research thrust is to design a holistic, deep learning based framework to efficiently generate or synthesize life-like small group conversational animations based on various user inputs. The third research thrust is to comprehensively evaluate the effectiveness and usefulness of the proposed framework via two selected applications: small group teleconferencing within virtual worlds, and crowd simulations with group conversations. The synthesis framework can potentially transform development of applications that deal with virtual human crowds such as the ones in shopping plazas, downtown streets, and airport waiting areas.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>08/13/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/15/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2005430</AwardID>
<Investigator>
<FirstName>Zhigang</FirstName>
<LastName>Deng</LastName>
<EmailAddress>zhigang.deng@gmail.com</EmailAddress>
<StartDate>08/13/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Houston</Name>
<CityName>Houston</CityName>
<ZipCode>772042015</ZipCode>
<PhoneNumber>7137435773</PhoneNumber>
<StreetAddress>4800 Calhoun Boulevard</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<ProgramElement>
<Code>7367</Code>
<Text>HCC-Human-Centered Computing</Text>
</ProgramElement>
<ProgramReference>
<Code>7367</Code>
<Text>Cyber-Human Systems</Text>
</ProgramReference>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
</Appropriation>
</Award>
</rootTag>
