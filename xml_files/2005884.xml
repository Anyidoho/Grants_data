<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>SHF: Small: Automatic, adaptive and massive parallel data processing on GPU/RDMA clusters in both synchronous and asynchronous modes</AwardTitle>
<AwardEffectiveDate>07/01/2020</AwardEffectiveDate>
<AwardExpirationDate>06/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>450000.00</AwardTotalIntnAmount>
<AwardAmount>450000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05010000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CCF</Abbreviation>
<LongName>Division of Computing and Communication Foundations</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Yuanyuan Yang</SignBlockName>
</ProgramOfficer>
<AbstractNarration>The computing ecosystem in both hardware and software is in a critical transition time, coming from several technology crises and inevitable trends. First, the continued performance improvement in general-purpose processors is no longer realistic. Second, conventional processors are increasingly inefficient in both performance and power consumption for various data-intensive applications. Finally, the deep software stack that has been developed for several decades, from instruction-set architecture all the way to the programming layer in the existing ecosystem, has added cumbersome processing and even unnecessary overhead in computing. To address the above-mentioned issues, this project remedies the computing ecosystem in an accelerator-based way. GPU (Graphic Processing Unit) and RDMA (Remote Data Memory Access) are the two external hardware accelerators considered in the project. It aims to turn efficient asynchronous computing into a reality on clusters of hardware accelerators of GPU and RDMA adaptively and automatically by removing three technical barriers in the existing ecosystem: (1) the programming-model barrier, (2) the hardware abstraction barrier, and (3) the automation barrier. The project strives to make broad and transformational impact. It is expected to influence the data-processing research community with new algorithms and effective systems implementation, and influence industries to improve their production systems in their daily computing operations serving society. The developed algorithms, source code and measurements are available online for a public and wide usage, benefiting both industrial and academic researchers. The research training to both undergraduate and graduate students address the concerns of lacking hardware-acceleration and data-analytics professionals in information technology and computing industries. The curriculum development introduces related research results to classrooms and the outreach activities encourage high school students to be interested in computing related college education. &lt;br/&gt;&lt;br/&gt;The existing computing environment does not provide programming models for asynchronous execution. It is even harder for asynchronous programming on GPU/RDMA clusters. The execution-model difference between CPUs and GPUs makes the system lack a common hardware abstraction for GPU computing and for RDMA communication and management. Asynchronous programming is hard, and an automatic tool to ensure its correctness and efficiency is highly desirable. This research project bridges the gap between asynchronous computing and GPU/RDMA. It develops an autonomous memory pool (AMP) interfacing GPU/RDMA clusters, where an intermediate representation is proposed to abstract the GPU execution and AMP constructed by an RDMA. A set of intermediate representations are developed to support asynchronous programming, so that users can easily express asynchronous computing in programming. In addition, an intermediate representation is developed to allow conventional synchronous programming to become automated asynchronous execution code. The system is tested and evaluated using representative data-processing workloads on large GPU/RDMA clusters.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/30/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/30/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2005884</AwardID>
<Investigator>
<FirstName>Xiaodong</FirstName>
<LastName>Zhang</LastName>
<EmailAddress>zhang@cse.ohio-state.edu</EmailAddress>
<StartDate>06/30/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Hao</FirstName>
<LastName>Wang</LastName>
<EmailAddress>wang.2721@osu.edu</EmailAddress>
<StartDate>06/30/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Ohio State University</Name>
<CityName>Columbus</CityName>
<ZipCode>432101016</ZipCode>
<PhoneNumber>6146888735</PhoneNumber>
<StreetAddress>Office of Sponsored Programs</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Ohio</StateName>
<StateCode>OH</StateCode>
</Institution>
<ProgramElement>
<Code>7798</Code>
<Text>Software &amp; Hardware Foundation</Text>
</ProgramElement>
<ProgramReference>
<Code>7923</Code>
<Text>SMALL PROJECT</Text>
</ProgramReference>
<ProgramReference>
<Code>7941</Code>
<Text>COMPUTER ARCHITECTURE</Text>
</ProgramReference>
</Award>
</rootTag>
