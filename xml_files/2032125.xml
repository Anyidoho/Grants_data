<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>RAPID: Human Sound Localization and Analytics</AwardTitle>
<AwardEffectiveDate>06/01/2020</AwardEffectiveDate>
<AwardExpirationDate>05/31/2021</AwardExpirationDate>
<AwardTotalIntnAmount>100000.00</AwardTotalIntnAmount>
<AwardAmount>100000</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05050000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>CNS</Abbreviation>
<LongName>Division Of Computer and Network Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Alexander Sprintson</SignBlockName>
</ProgramOfficer>
<AbstractNarration>COVID-19 is spreading at an unprecedented rate resulting in the death of so many people all over the world. Social distancing is so far the most effective method to limit its spread. However, manually enforcing social distancing is not only labor-intensive but also error-prone and even dangerous due to possible physical contact. This project proposes to develop techniques and mobile systems that localize human sound such as cough and voice and alarm a user when someone is within the social distance.  If successful, this work will significantly advance the state-of-the-art in wireless sensing and localization. To maximize the impact, the researchers will collaborate with industry and local community and release software to the public. The research outcome will also be incorporated into the graduate and undergraduate curriculum. &lt;br/&gt;&lt;br/&gt;The proposed research aims to develop algorithms and systems to localize uncontrolled and unknown human sound. A unique advantage is that it does not require cooperation from other phones and whoever uses it can immediately benefit from it. It exploits the phone mobility as the user moves to enable localization. The multi-resolution analysis will be performed on low-frequency voice signals to further enhance accuracy. When another phone is cooperating, it will further leverage the time of flight between the two phones to improve the performance.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>06/01/2020</MinAmdLetterDate>
<MaxAmdLetterDate>06/01/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2032125</AwardID>
<Investigator>
<FirstName>Lili</FirstName>
<LastName>Qiu</LastName>
<EmailAddress>lili@cs.utexas.edu</EmailAddress>
<StartDate>06/01/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>University of Texas at Austin</Name>
<CityName>Austin</CityName>
<ZipCode>787595316</ZipCode>
<PhoneNumber>5124716424</PhoneNumber>
<StreetAddress>3925 W Braker Lane, Ste 3.340</StreetAddress>
<CountryName>United States</CountryName>
<StateName>Texas</StateName>
<StateCode>TX</StateCode>
</Institution>
<ProgramElement>
<Code>158Y</Code>
<Text>COVID-19 Research</Text>
</ProgramElement>
<ProgramReference>
<Code>096Z</Code>
<Text>COVID-19 Research</Text>
</ProgramReference>
<ProgramReference>
<Code>7914</Code>
<Text>RAPID</Text>
</ProgramReference>
<Appropriation>
<Code>1N20</Code>
</Appropriation>
</Award>
</rootTag>
