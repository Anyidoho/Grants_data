<?xml version="1.0" encoding="UTF-8"?>
<rootTag>
<Award>
<AwardTitle>NRI: FND: Using Multi-Modal Data to Make Robotic Grasp Algorithms Aware of Human Preferences for Safe Collaborative Robot-Human Handover Interactions with Novel Objects</AwardTitle>
<AwardEffectiveDate>10/15/2020</AwardEffectiveDate>
<AwardExpirationDate>09/30/2023</AwardExpirationDate>
<AwardTotalIntnAmount>304935.00</AwardTotalIntnAmount>
<AwardAmount>304935</AwardAmount>
<AwardInstrument>
<Value>Standard Grant</Value>
</AwardInstrument>
<Organization>
<Code>05020000</Code>
<Directorate>
<Abbreviation>CSE</Abbreviation>
<LongName>Direct For Computer &amp; Info Scie &amp; Enginr</LongName>
</Directorate>
<Division>
<Abbreviation>IIS</Abbreviation>
<LongName>Div Of Information &amp; Intelligent Systems</LongName>
</Division>
</Organization>
<ProgramOfficer>
<SignBlockName>Scott Acton</SignBlockName>
</ProgramOfficer>
<AbstractNarration>This project contributes advancements in promoting safe collaborative robot-to-human handovers by making robots with manipulator arms aware of human preferences for interactions with objects. In environments such as healthcare facilities, warehousing, retail, engine repair, and aircraft assembly, where robots may be expected to collaborate with humans for successful accomplishment of tasks, it is essential that robotic manipulators hand over objects such that people can optimally hold them, without fear of the object falling or the person being injured by the gripper or arm, and without the inconvenience of the object being unreachable. To enable safe handovers, the project will provide algorithms that use data on human interactions with objects captured from multiple viewpoints to automatically predict preferred locations of human grasp on objects, optimal orientation and distance of the object from the person, and safe point of release of the object by manipulator grippers. The research team will reach out to two-year and four-year colleges with limited technological opportunities in the North Country to provide research opportunities to women and students from underrepresented communities.&lt;br/&gt;&lt;br/&gt;The project advances research in ubiquitous co-robots by providing holistic fine-grained insight through multi-modal sensing on natural behaviors of people as they interact with each other and with objects in their environments. The project accomplishes three objectives to address the gap on propagating understanding of human handover preferences to large collections of novel in-the-wild objects for customizability of co-robots to new environments. First, the research team will collect a large multi-viewpoint multi-modal dataset on two-person handovers and perform empirical analysis of the collected data to understand preferences on hold locations, end pose, and release point using subject ratings of object presentations. Modalities used will consist of depth cameras to acquire understanding on object geometry and spatial relationships, and thermal cameras to analyze locations of human contact based on heat transferred to object surfaces. This work will provide a quantitative decomposition of human preferences for handover parameters in terms of geometric form and functionality of objects. Second, the team will create perception algorithms based on probabilistic models to perform prediction of handover parameters ranked in order of preference using depth images of objects as input. This work enables equipping co-robots with human-like awareness of diversity in preferences, and the priorities that people assign to interactions. Third, the team will provide robotic manipulators that use the trained perception algorithms to perform handover manipulations on novel objects while being aware of human behavior. Successful accomplishment of the project activities will enable rapid propagation of robotic manipulators aware of human handover behavior to new objects and environments for enhanced social acceptability of co-robots.&lt;br/&gt;&lt;br/&gt;This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.</AbstractNarration>
<MinAmdLetterDate>09/08/2020</MinAmdLetterDate>
<MaxAmdLetterDate>10/13/2020</MaxAmdLetterDate>
<ARRAAmount/>
<AwardID>2023998</AwardID>
<Investigator>
<FirstName>Natasha</FirstName>
<LastName>Banerjee</LastName>
<EmailAddress>nbanerje@clarkson.edu</EmailAddress>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Principal Investigator</RoleCode>
</Investigator>
<Investigator>
<FirstName>Sean</FirstName>
<LastName>Banerjee</LastName>
<EmailAddress>sbanerje@clarkson.edu</EmailAddress>
<StartDate>09/08/2020</StartDate>
<EndDate/>
<RoleCode>Co-Principal Investigator</RoleCode>
</Investigator>
<Institution>
<Name>Clarkson University</Name>
<CityName>Potsdam</CityName>
<ZipCode>136761401</ZipCode>
<PhoneNumber>3152686475</PhoneNumber>
<StreetAddress>8 Clarkson Avenue</StreetAddress>
<CountryName>United States</CountryName>
<StateName>New York</StateName>
<StateCode>NY</StateCode>
</Institution>
<ProgramElement>
<Code>8013</Code>
<Text>NRI-National Robotics Initiati</Text>
</ProgramElement>
<ProgramReference>
<Code>8086</Code>
<Text>Natl Robotics Initiative (NRI)</Text>
</ProgramReference>
<ProgramReference>
<Code>9102</Code>
<Text>WOMEN, MINORITY, DISABLED, NEC</Text>
</ProgramReference>
<Appropriation>
<Code>0120</Code>
</Appropriation>
</Award>
</rootTag>
